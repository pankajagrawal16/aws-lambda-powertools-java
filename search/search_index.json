{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Powertools is a suite of utilities for AWS Lambda Functions that makes tracing with AWS X-Ray, structured logging and creating custom metrics asynchronously easier. Looking for a quick run through of the core utilities? Check out this detailed blog post with a practical example. Tenets \u00b6 This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes. AWS Lambda only \u2013 We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported. Eases the adoption of best practices \u2013 The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional. Keep it lean \u2013 Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time. We strive for backwards compatibility \u2013 New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined. We work backwards from the community \u2013 We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs) Idiomatic \u2013 Utilities follow programming language idioms and language-specific best practices. Install \u00b6 Powertools dependencies are available in Maven Central. You can use your favourite dependency management tool to install it Maven Gradle Quick hello world examples using SAM CLI You can use SAM to quickly setup a serverless project including AWS Lambda Powertools Java. 1 sam init --location gh:aws-samples/cookiecutter-aws-sam-powertools-java For more information about the project and available options refer to this repository Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> <version> 1.2.0 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> <version> 1.2.0 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> <version> 1.2.0 </version> </dependency> ... </dependencies> ... <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Note: If you are working with lambda function on runtime post java8, please refer issue for workaround. Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 plugins { id 'java' id 'aspectj.AspectjGradlePlugin' version '0.0.6' } repositories { jcenter () } dependencies { implementation 'software.amazon.lambda:powertools-tracing:1.2.0' aspectpath 'software.amazon.lambda:powertools-tracing:1.2.0' implementation 'software.amazon.lambda:powertools-logging:1.2.0' aspectpath 'software.amazon.lambda:powertools-logging:1.2.0' implementation 'software.amazon.lambda:powertools-metrics:1.2.0' aspectpath 'software.amazon.lambda:powertools-metrics:1.2.0' } Note: Please add aspectjVersion = '1.9.6' to the gradle.properties file. The aspectj plugin works at the moment with gradle 5.x only if you are using java 8 as runtime. Please refer to open issue for more details. Environment variables \u00b6 Info Explicit parameters take precedence over environment variables. Environment variable Description Utility POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging POWERTOOLS_LOG_LEVEL Sets logging level Logging POWERTOOLS_TRACER_CAPTURE_RESPONSE Enables/Disables tracing mode to capture method response Tracing POWERTOOLS_TRACER_CAPTURE_ERROR Enables/Disables tracing mode to capture method error Tracing","title":"Homepage"},{"location":"#tenets","text":"This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes. AWS Lambda only \u2013 We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported. Eases the adoption of best practices \u2013 The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional. Keep it lean \u2013 Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time. We strive for backwards compatibility \u2013 New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined. We work backwards from the community \u2013 We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs) Idiomatic \u2013 Utilities follow programming language idioms and language-specific best practices.","title":"Tenets"},{"location":"#install","text":"Powertools dependencies are available in Maven Central. You can use your favourite dependency management tool to install it Maven Gradle Quick hello world examples using SAM CLI You can use SAM to quickly setup a serverless project including AWS Lambda Powertools Java. 1 sam init --location gh:aws-samples/cookiecutter-aws-sam-powertools-java For more information about the project and available options refer to this repository Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> <version> 1.2.0 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> <version> 1.2.0 </version> </dependency> <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> <version> 1.2.0 </version> </dependency> ... </dependencies> ... <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-tracing </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-logging </artifactId> </aspectLibrary> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-metrics </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Note: If you are working with lambda function on runtime post java8, please refer issue for workaround. Gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 plugins { id 'java' id 'aspectj.AspectjGradlePlugin' version '0.0.6' } repositories { jcenter () } dependencies { implementation 'software.amazon.lambda:powertools-tracing:1.2.0' aspectpath 'software.amazon.lambda:powertools-tracing:1.2.0' implementation 'software.amazon.lambda:powertools-logging:1.2.0' aspectpath 'software.amazon.lambda:powertools-logging:1.2.0' implementation 'software.amazon.lambda:powertools-metrics:1.2.0' aspectpath 'software.amazon.lambda:powertools-metrics:1.2.0' } Note: Please add aspectjVersion = '1.9.6' to the gradle.properties file. The aspectj plugin works at the moment with gradle 5.x only if you are using java 8 as runtime. Please refer to open issue for more details.","title":"Install"},{"location":"#environment-variables","text":"Info Explicit parameters take precedence over environment variables. Environment variable Description Utility POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging POWERTOOLS_LOG_LEVEL Sets logging level Logging POWERTOOLS_TRACER_CAPTURE_RESPONSE Enables/Disables tracing mode to capture method response Tracing POWERTOOLS_TRACER_CAPTURE_ERROR Enables/Disables tracing mode to capture method error Tracing","title":"Environment variables"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project follows Keep a Changelog format for changes and adheres to Semantic Versioning . [Unreleased] \u00b6 [1.3.0] - Coming soon! \u00b6","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. This project follows Keep a Changelog format for changes and adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#130-coming-soon","text":"","title":"[1.3.0] - Coming soon!"},{"location":"core/logging/","text":"Logging provides an opinionated logger with output structured as JSON. Key features Capture key fields from Lambda context, cold start and structures logging output as JSON Log Lambda event when instructed, disabled by default, can be enabled explicitly via annotation param Append additional keys to structured log at any point in time Initialization \u00b6 Powertools extends the functionality of Log4J. Below is an example log4j2.xml file, with the LambdaJsonLayout configured. log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration packages= \"com.amazonaws.services.lambda.runtime.log4j2\" > <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <LambdaJsonLayout compact= \"true\" eventEol= \"true\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> You can also override log level by setting POWERTOOLS_LOG_LEVEL env var. Here is an example using AWS Serverless Application Model (SAM) template.yaml 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOG_LEVEL : DEBUG POWERTOOLS_SERVICE_NAME : example You can also explicitly set a service name via POWERTOOLS_SERVICE_NAME env var. This sets service key that will be present across all log statements. Standard structured keys \u00b6 Your logs will always include the following keys to your structured logging: Key Type Example Description timestamp String \"2020-05-24 18:17:33,774\" Timestamp of actual log statement level String \"INFO\" Logging level coldStart Boolean true ColdStart value. service String \"payment\" Service name defined. \"service_undefined\" will be used if unknown samplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case message String \"Collecting payment\" Log statement value. Unserializable JSON values will be casted to string functionName String \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" functionVersion String \"12\" functionMemorySize String \"128\" functionArn String \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" xray_trace_id String \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing function_request_id String \"899856cb-83d1-40d7-8611-9e78f15f32f4\"\" AWS Request ID from lambda context Capturing context Lambda info \u00b6 You can enrich your structured logs with key Lambda context information via logEvent annotation parameter. You can also explicitly log any incoming event using logEvent param. Refer Override default object mapper to customise what is logged. Warning Log event is disabled by default to prevent sensitive info being logged. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; import software.amazon.lambda.logging.LoggingUtils ; import software.amazon.lambda.logging.Logging ; ... /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } AppLogEvent.java 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class AppLogEvent implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Appending additional keys \u00b6 You can append your own keys to your existing logs via appendKey . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... LoggingUtils . appendKey ( \"test\" , \"willBeLogged\" ); ... ... Map < String , String > customKeys = new HashMap <> (); customKeys . put ( \"test\" , \"value\" ); customKeys . put ( \"test1\" , \"value1\" ); LoggingUtils . appendKeys ( customKeys ); ... } } Override default object mapper \u00b6 You can optionally choose to override default object mapper which is used to serialize lambda function events. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); static { ObjectMapper objectMapper = new ObjectMapper (); LoggingUtils . defaultObjectMapper ( objectMapper ); } @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Sampling debug logs \u00b6 You can dynamically set a percentage of your logs to DEBUG level via env var POWERTOOLS_LOGGER_SAMPLE_RATE or via samplingRate attribute on annotation. Info Configuration on environment variable is given precedence over sampling rate configuration on annotation, provided it's in valid value range. Sampling via annotation attribute 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( samplingRate = 0.5 ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Sampling via environment variable 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOGGER_SAMPLE_RATE : 0.5","title":"Logging"},{"location":"core/logging/#initialization","text":"Powertools extends the functionality of Log4J. Below is an example log4j2.xml file, with the LambdaJsonLayout configured. log4j2.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration packages= \"com.amazonaws.services.lambda.runtime.log4j2\" > <Appenders> <Console name= \"JsonAppender\" target= \"SYSTEM_OUT\" > <LambdaJsonLayout compact= \"true\" eventEol= \"true\" /> </Console> </Appenders> <Loggers> <Logger name= \"JsonLogger\" level= \"INFO\" additivity= \"false\" > <AppenderRef ref= \"JsonAppender\" /> </Logger> <Root level= \"info\" > <AppenderRef ref= \"JsonAppender\" /> </Root> </Loggers> </Configuration> You can also override log level by setting POWERTOOLS_LOG_LEVEL env var. Here is an example using AWS Serverless Application Model (SAM) template.yaml 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOG_LEVEL : DEBUG POWERTOOLS_SERVICE_NAME : example You can also explicitly set a service name via POWERTOOLS_SERVICE_NAME env var. This sets service key that will be present across all log statements.","title":"Initialization"},{"location":"core/logging/#standard-structured-keys","text":"Your logs will always include the following keys to your structured logging: Key Type Example Description timestamp String \"2020-05-24 18:17:33,774\" Timestamp of actual log statement level String \"INFO\" Logging level coldStart Boolean true ColdStart value. service String \"payment\" Service name defined. \"service_undefined\" will be used if unknown samplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case message String \"Collecting payment\" Log statement value. Unserializable JSON values will be casted to string functionName String \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" functionVersion String \"12\" functionMemorySize String \"128\" functionArn String \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" xray_trace_id String \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing function_request_id String \"899856cb-83d1-40d7-8611-9e78f15f32f4\"\" AWS Request ID from lambda context","title":"Standard structured keys"},{"location":"core/logging/#capturing-context-lambda-info","text":"You can enrich your structured logs with key Lambda context information via logEvent annotation parameter. You can also explicitly log any incoming event using logEvent param. Refer Override default object mapper to customise what is logged. Warning Log event is disabled by default to prevent sensitive info being logged. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; import software.amazon.lambda.logging.LoggingUtils ; import software.amazon.lambda.logging.Logging ; ... /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } AppLogEvent.java 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class AppLogEvent implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } }","title":"Capturing context Lambda info"},{"location":"core/logging/#appending-additional-keys","text":"You can append your own keys to your existing logs via appendKey . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... LoggingUtils . appendKey ( \"test\" , \"willBeLogged\" ); ... ... Map < String , String > customKeys = new HashMap <> (); customKeys . put ( \"test\" , \"value\" ); customKeys . put ( \"test1\" , \"value1\" ); LoggingUtils . appendKeys ( customKeys ); ... } }","title":"Appending additional keys"},{"location":"core/logging/#override-default-object-mapper","text":"You can optionally choose to override default object mapper which is used to serialize lambda function events. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); static { ObjectMapper objectMapper = new ObjectMapper (); LoggingUtils . defaultObjectMapper ( objectMapper ); } @Logging ( logEvent = true ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } }","title":"Override default object mapper"},{"location":"core/logging/#sampling-debug-logs","text":"You can dynamically set a percentage of your logs to DEBUG level via env var POWERTOOLS_LOGGER_SAMPLE_RATE or via samplingRate attribute on annotation. Info Configuration on environment variable is given precedence over sampling rate configuration on annotation, provided it's in valid value range. Sampling via annotation attribute 1 2 3 4 5 6 7 8 9 10 11 12 /** * Handler for requests to Lambda function. */ public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { Logger log = LogManager . getLogger (); @Logging ( samplingRate = 0.5 ) public APIGatewayProxyResponseEvent handleRequest ( final APIGatewayProxyRequestEvent input , final Context context ) { ... } } Sampling via environment variable 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_LOGGER_SAMPLE_RATE : 0.5","title":"Sampling debug logs"},{"location":"core/metrics/","text":"Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF). These metrics can be visualized through Amazon CloudWatch Console . Key features Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob). Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc). Metrics are created asynchronously by the CloudWatch service, no custom stacks needed. Context manager to create a one off metric with a different dimension. Terminologies \u00b6 If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility: Namespace . It's the highest level container that will group multiple metrics from multiple services for a given application, for example ServerlessEcommerce . Dimensions . Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example ColdStart metric by Payment service . Metric terminology, visually explained Getting started \u00b6 Metric has two global settings that will be used across all metrics emitted: Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. ServerlessAirline POWERTOOLS_METRICS_NAMESPACE namespace Service Optionally, sets service metric dimension across all metrics e.g. payment POWERTOOLS_SERVICE_NAME service Use your application or main service as the metric namespace to easily group all metrics template.yaml 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_SERVICE_NAME : payment POWERTOOLS_METRICS_NAMESPACE : ServerlessAirline MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { ... } } You can initialize Metrics anywhere in your code as many times as you need - It'll keep track of your aggregate metrics in memory. Creating metrics \u00b6 You can create metrics using putMetric , and manually create dimensions for all your aggregate metrics using putDimensions . MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger . putDimensions ( DimensionSet . of ( \"environment\" , \"prod\" )); metricsLogger . putMetric ( \"SuccessfulBooking\" , 1 , Unit . COUNT ); ... } } The Unit enum facilitate finding a supported metric unit by CloudWatch. Metrics overflow CloudWatch EMF supports a max of 100 metrics. Metrics utility will flush all metrics when adding the 100th metric while subsequent metrics will be aggregated into a new EMF object, for your convenience. Flushing metrics \u00b6 The @Metrics annotation validates , serializes , and flushes all your metrics. During metrics validation, if no metrics are provided no exception will be raised. If metrics are provided, and any of the following criteria are not met, ValidationException exception will be raised. Metric validation Minimum of 1 dimension Maximum of 9 dimensions If you want to ensure that at least one metric is emitted, you can pass raiseOnEmptyMetrics = true to the @Metrics annotation: MetricsRaiseOnEmpty.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsRaiseOnEmpty implements RequestHandler < Object , Object > { @Override @Metrics ( raiseOnEmptyMetrics = true ) public Object handleRequest ( Object input , Context context ) { ... } } Capturing cold start metric \u00b6 You can capture cold start metrics automatically with @Metrics via the captureColdStart variable. MetricsColdStart.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsColdStart implements RequestHandler < Object , Object > { @Override @Metrics ( captureColdStart = true ) public Object handleRequest ( Object input , Context context ) { ... } } If it's a cold start invocation, this feature will: Create a separate EMF blob solely containing a metric named ColdStart Add FunctionName and Service dimensions This has the advantage of keeping cold start metric separate from your application metrics. Advanced \u00b6 Adding metadata \u00b6 You can use putMetadata for advanced use cases, where you want to metadata as part of the serialized metrics object. Info This will not be available during metrics visualization, use dimensions for this purpose. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class App implements RequestHandler < Object , Object > { @Override @Metrics ( namespace = \"ServerlessAirline\" , service = \"payment\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger (). putMetric ( \"CustomMetric1\" , 1 , Unit . COUNT ); metricsLogger (). putMetadata ( \"booking_id\" , \"1234567890\" ); ... } } This will be available in CloudWatch Logs to ease operations on high cardinal data. Creating a metric with a different dimension \u00b6 CloudWatch EMF uses the same dimensions across all your metrics. Use withSingleMetric if you have a metric that should have different dimensions. Info Generally, this would be an edge case since you pay for unique metric . Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value) App.java 1 2 3 4 5 6 7 8 9 10 11 import static software.amazon.lambda.powertools.metrics.MetricsUtils.withSingleMetric ; public class App implements RequestHandler < Object , Object > { @Override public Object handleRequest ( Object input , Context context ) { withSingleMetric ( \"CustomMetrics2\" , 1 , Unit . COUNT , \"Another\" , ( metric ) -> { metric . setDimensions ( DimensionSet . of ( \"AnotherService\" , \"CustomService\" )); }); } }","title":"Metrics"},{"location":"core/metrics/#terminologies","text":"If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility: Namespace . It's the highest level container that will group multiple metrics from multiple services for a given application, for example ServerlessEcommerce . Dimensions . Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example ColdStart metric by Payment service . Metric terminology, visually explained","title":"Terminologies"},{"location":"core/metrics/#getting-started","text":"Metric has two global settings that will be used across all metrics emitted: Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. ServerlessAirline POWERTOOLS_METRICS_NAMESPACE namespace Service Optionally, sets service metric dimension across all metrics e.g. payment POWERTOOLS_SERVICE_NAME service Use your application or main service as the metric namespace to easily group all metrics template.yaml 1 2 3 4 5 6 7 8 9 10 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Environment : Variables : POWERTOOLS_SERVICE_NAME : payment POWERTOOLS_METRICS_NAMESPACE : ServerlessAirline MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { ... } } You can initialize Metrics anywhere in your code as many times as you need - It'll keep track of your aggregate metrics in memory.","title":"Getting started"},{"location":"core/metrics/#creating-metrics","text":"You can create metrics using putMetric , and manually create dimensions for all your aggregate metrics using putDimensions . MetricsEnabledHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class MetricsEnabledHandler implements RequestHandler < Object , Object > { MetricsLogger metricsLogger = MetricsUtils . metricsLogger (); @Override @Metrics ( namespace = \"ExampleApplication\" , service = \"booking\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger . putDimensions ( DimensionSet . of ( \"environment\" , \"prod\" )); metricsLogger . putMetric ( \"SuccessfulBooking\" , 1 , Unit . COUNT ); ... } } The Unit enum facilitate finding a supported metric unit by CloudWatch. Metrics overflow CloudWatch EMF supports a max of 100 metrics. Metrics utility will flush all metrics when adding the 100th metric while subsequent metrics will be aggregated into a new EMF object, for your convenience.","title":"Creating metrics"},{"location":"core/metrics/#flushing-metrics","text":"The @Metrics annotation validates , serializes , and flushes all your metrics. During metrics validation, if no metrics are provided no exception will be raised. If metrics are provided, and any of the following criteria are not met, ValidationException exception will be raised. Metric validation Minimum of 1 dimension Maximum of 9 dimensions If you want to ensure that at least one metric is emitted, you can pass raiseOnEmptyMetrics = true to the @Metrics annotation: MetricsRaiseOnEmpty.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsRaiseOnEmpty implements RequestHandler < Object , Object > { @Override @Metrics ( raiseOnEmptyMetrics = true ) public Object handleRequest ( Object input , Context context ) { ... } }","title":"Flushing metrics"},{"location":"core/metrics/#capturing-cold-start-metric","text":"You can capture cold start metrics automatically with @Metrics via the captureColdStart variable. MetricsColdStart.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.metrics.Metrics ; public class MetricsColdStart implements RequestHandler < Object , Object > { @Override @Metrics ( captureColdStart = true ) public Object handleRequest ( Object input , Context context ) { ... } } If it's a cold start invocation, this feature will: Create a separate EMF blob solely containing a metric named ColdStart Add FunctionName and Service dimensions This has the advantage of keeping cold start metric separate from your application metrics.","title":"Capturing cold start metric"},{"location":"core/metrics/#advanced","text":"","title":"Advanced"},{"location":"core/metrics/#adding-metadata","text":"You can use putMetadata for advanced use cases, where you want to metadata as part of the serialized metrics object. Info This will not be available during metrics visualization, use dimensions for this purpose. App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 import software.amazon.lambda.powertools.metrics.Metrics ; import software.amazon.cloudwatchlogs.emf.logger.MetricsLogger ; public class App implements RequestHandler < Object , Object > { @Override @Metrics ( namespace = \"ServerlessAirline\" , service = \"payment\" ) public Object handleRequest ( Object input , Context context ) { metricsLogger (). putMetric ( \"CustomMetric1\" , 1 , Unit . COUNT ); metricsLogger (). putMetadata ( \"booking_id\" , \"1234567890\" ); ... } } This will be available in CloudWatch Logs to ease operations on high cardinal data.","title":"Adding metadata"},{"location":"core/metrics/#creating-a-metric-with-a-different-dimension","text":"CloudWatch EMF uses the same dimensions across all your metrics. Use withSingleMetric if you have a metric that should have different dimensions. Info Generally, this would be an edge case since you pay for unique metric . Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value) App.java 1 2 3 4 5 6 7 8 9 10 11 import static software.amazon.lambda.powertools.metrics.MetricsUtils.withSingleMetric ; public class App implements RequestHandler < Object , Object > { @Override public Object handleRequest ( Object input , Context context ) { withSingleMetric ( \"CustomMetrics2\" , 1 , Unit . COUNT , \"Another\" , ( metric ) -> { metric . setDimensions ( DimensionSet . of ( \"AnotherService\" , \"CustomService\" )); }); } }","title":"Creating a metric with a different dimension"},{"location":"core/tracing/","text":"Powertools tracing is an opinionated thin wrapper for AWS X-Ray Java SDK a provides functionality to reduce the overhead of performing common tracing tasks. Key Features Capture cold start as annotation, and responses as well as full exceptions as metadata Helper methods to improve the developer experience of creating new X-Ray subsegments. Better developer experience when developing with multiple threads. Auto patch supported modules by AWS X-Ray Initialization Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray. Example using AWS Serverless Application Model (SAM) template.yaml 1 2 3 4 5 6 7 8 9 10 11 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Tracing : Active Environment : Variables : POWERTOOLS_SERVICE_NAME : example The Powertools service name is used as the X-Ray namespace. This can be set using the environment variable POWERTOOLS_SERVICE_NAME Lambda handler \u00b6 To enable Powertools tracing to your function add the @Tracing annotation to your handleRequest` method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize segment name that appears in traces. Tracing annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { businessLogic1 (); businessLogic2 (); } @Tracing public void businessLogic1 (){ } @Tracing public void businessLogic2 (){ } } Custom Segment names 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( segmentName = \"yourCustomName\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } By default, this annotation will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR as needed. Optionally, you can override behavior by different supported captureMode to record response, exception or both. Returning sensitive information from your Lambda handler or functions, where Tracing is used? You can disable annotation from capturing their responses and exception as tracing metadata with captureMode=DISABLED or globally by setting environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR to false Disable on annotation 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( captureMode = CaptureMode . DISABLED ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } Disable Globally 1 2 3 4 5 6 7 8 9 10 11 12 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Tracing : Active Environment : Variables : POWERTOOLS_TRACER_CAPTURE_RESPONSE : false POWERTOOLS_TRACER_CAPTURE_ERROR : false Annotations & Metadata \u00b6 Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions. Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object. Annotations You can add annotations using putAnnotation() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putAnnotation ( \"annotation\" , \"value\" ); } } Metadata You can add metadata using putMetadata() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putMetadata ( \"content\" , \"value\" ); } } Utilities \u00b6 Tracing modules comes with certain utility method when you don't want to use annotation for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below. Functional Api 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . withSubsegment ( \"loggingResponse\" , subsegment -> { // Some business logic }); TracingUtils . withSubsegment ( \"localNamespace\" , \"loggingResponse\" , subsegment -> { // Some business logic }); } } Multi Threaded Programming 1 2 3 4 5 6 7 8 9 10 11 12 13 import static software.amazon.lambda.powertools.tracing.TracingUtils.withEntitySubsegment ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // Extract existing trace data Entity traceEntity = AWSXRay . getTraceEntity (); Thread anotherThread = new Thread (() -> withEntitySubsegment ( \"inlineLog\" , traceEntity , subsegment -> { // Business logic in separate thread })); } } Instrumenting SDK clients and HTTP calls \u00b6 User should make sure to instrument the SDK clients explicitly based on the function dependency. Refer details on how to instrument SDK client with Xray and outgoing http calls .","title":"Tracing"},{"location":"core/tracing/#lambda-handler","text":"To enable Powertools tracing to your function add the @Tracing annotation to your handleRequest` method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize segment name that appears in traces. Tracing annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { businessLogic1 (); businessLogic2 (); } @Tracing public void businessLogic1 (){ } @Tracing public void businessLogic2 (){ } } Custom Segment names 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( segmentName = \"yourCustomName\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } By default, this annotation will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR as needed. Optionally, you can override behavior by different supported captureMode to record response, exception or both. Returning sensitive information from your Lambda handler or functions, where Tracing is used? You can disable annotation from capturing their responses and exception as tracing metadata with captureMode=DISABLED or globally by setting environment variables POWERTOOLS_TRACER_CAPTURE_RESPONSE and POWERTOOLS_TRACER_CAPTURE_ERROR to false Disable on annotation 1 2 3 4 5 6 public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing ( captureMode = CaptureMode . DISABLED ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { ... } Disable Globally 1 2 3 4 5 6 7 8 9 10 11 12 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : ... Runtime : java8 Tracing : Active Environment : Variables : POWERTOOLS_TRACER_CAPTURE_RESPONSE : false POWERTOOLS_TRACER_CAPTURE_ERROR : false","title":"Lambda handler"},{"location":"core/tracing/#annotations-metadata","text":"Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions. Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object. Annotations You can add annotations using putAnnotation() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putAnnotation ( \"annotation\" , \"value\" ); } } Metadata You can add metadata using putMetadata() method from TracingUtils 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Tracing public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . putMetadata ( \"content\" , \"value\" ); } }","title":"Annotations &amp; Metadata"},{"location":"core/tracing/#utilities","text":"Tracing modules comes with certain utility method when you don't want to use annotation for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below. Functional Api 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.tracing.Tracing ; import software.amazon.lambda.powertools.tracing.TracingUtils ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { TracingUtils . withSubsegment ( \"loggingResponse\" , subsegment -> { // Some business logic }); TracingUtils . withSubsegment ( \"localNamespace\" , \"loggingResponse\" , subsegment -> { // Some business logic }); } } Multi Threaded Programming 1 2 3 4 5 6 7 8 9 10 11 12 13 import static software.amazon.lambda.powertools.tracing.TracingUtils.withEntitySubsegment ; public class App implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // Extract existing trace data Entity traceEntity = AWSXRay . getTraceEntity (); Thread anotherThread = new Thread (() -> withEntitySubsegment ( \"inlineLog\" , traceEntity , subsegment -> { // Business logic in separate thread })); } }","title":"Utilities"},{"location":"core/tracing/#instrumenting-sdk-clients-and-http-calls","text":"User should make sure to instrument the SDK clients explicitly based on the function dependency. Refer details on how to instrument SDK client with Xray and outgoing http calls .","title":"Instrumenting SDK clients and HTTP calls"},{"location":"utilities/batch/","text":"The SQS batch processing utility provides a way to handle partial failures when processing batches of messages from SQS. Key Features Prevent successfully processed messages from being returned to SQS A simple interface for individually processing messages from a batch Background When using SQS as a Lambda event source mapping, Lambda functions can be triggered with a batch of messages from SQS. If your function fails to process any message from the batch, the entire batch returns to your SQS queue, and your Lambda function will be triggered with the same batch again. With this utility, messages within a batch will be handled individually - only messages that were not successfully processed are returned to the queue. Warning While this utility lowers the chance of processing messages more than once, it is not guaranteed. We recommend implementing processing logic in an idempotent manner wherever possible. More details on how Lambda works with SQS can be found in the AWS documentation Install \u00b6 To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.2.0 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Gradle 1 2 3 4 5 dependencies { ... implementation 'software.amazon.lambda:powertools-sqs:1.2.0' aspectpath 'software.amazon.lambda:powertools-sqs:1.2.0' } IAM Permissions This utility requires additional permissions to work as expected. Lambda functions using this utility require the sqs:GetQueueUrl and sqs:DeleteMessageBatch permission. Processing messages from SQS \u00b6 You can use either SqsBatch annotation , or SqsUtils Utility API as a fluent API. Both have nearly the same behaviour when it comes to processing messages from the batch: Entire batch has been successfully processed , where your Lambda handler returned successfully, we will let SQS delete the batch to optimize your cost Entire Batch has been partially processed successfully , where exceptions were raised within your SqsMessageHandler interface implementation, we will: 1) Delete successfully processed messages from the queue by directly calling sqs:DeleteMessageBatch 2) Raise SQSBatchProcessingException to ensure failed messages return to your SQS queue The only difference is that SqsUtils Utility API will give you access to return from the processed messages if you need. Exception SQSBatchProcessingException thrown from the utility will have access to both successful and failed messaged along with failure exceptions. Functional Interface SqsMessageHandler \u00b6 Both annotation and SqsUtils Utility API requires an implementation of functional interface SqsMessageHandler . This implementation is responsible for processing each individual message from the batch, and to raise an exception if unable to process any of the messages sent. Any non-exception/successful return from your record handler function will instruct utility to queue up each individual message for deletion. SqsBatch annotation \u00b6 When using this annotation, you need provide a class implementation of SqsMessageHandler that will process individual messages from the batch - It should raise an exception if it is unable to process the record. All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch: Any successfully processed messages , we will delete them from the queue via sqs:DeleteMessageBatch Any unprocessed messages detected , we will raise SQSBatchProcessingException to ensure failed messages return to your SQS queue Warning You will not have access to the processed messages within the Lambda Handler - all processing logic will and should be performed by the implemented SqsMessageHandler # process () function. AppSqsEvent.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( SampleMessageHandler . class ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } SqsUtils Utility API \u00b6 If you require access to the result of processed messages, you can use this utility. The result from calling SqsUtils # batchProcessor () on the context manager will be a list of all the return values from your SqsMessageHandler # process () function. You can also use the utility in functional way by providing inline implementation of functional interface SqsMessageHandler # process () Utility API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } Function implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , ( message ) -> { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; }); return returnValues ; } } Passing custom SqsClient \u00b6 If you need to pass custom SqsClient such as region to the SDK, you can pass your own SqsClient to be used by utility either for SqsBatch annotation , or SqsUtils Utility API . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { static { SqsUtils . overrideSqsClient ( SqsClient . builder () . build ()); } @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } Suppressing exceptions \u00b6 If you want to disable the default behavior where SQSBatchProcessingException is raised if there are any exception, you can pass the suppressException boolean argument. Within SqsBatch annotation 1 2 3 4 5 @Override @SqsBatch ( value = SampleMessageHandler . class , suppressException = true ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } Within SqsUtils Utility API 1 2 3 4 5 6 @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , true , SampleMessageHandler . class ); return returnValues ; }","title":"SQS Batch Processing"},{"location":"utilities/batch/#install","text":"To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 <dependencies> ... <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.2.0 </version> </dependency> ... </dependencies> <!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --> <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Gradle 1 2 3 4 5 dependencies { ... implementation 'software.amazon.lambda:powertools-sqs:1.2.0' aspectpath 'software.amazon.lambda:powertools-sqs:1.2.0' } IAM Permissions This utility requires additional permissions to work as expected. Lambda functions using this utility require the sqs:GetQueueUrl and sqs:DeleteMessageBatch permission.","title":"Install"},{"location":"utilities/batch/#processing-messages-from-sqs","text":"You can use either SqsBatch annotation , or SqsUtils Utility API as a fluent API. Both have nearly the same behaviour when it comes to processing messages from the batch: Entire batch has been successfully processed , where your Lambda handler returned successfully, we will let SQS delete the batch to optimize your cost Entire Batch has been partially processed successfully , where exceptions were raised within your SqsMessageHandler interface implementation, we will: 1) Delete successfully processed messages from the queue by directly calling sqs:DeleteMessageBatch 2) Raise SQSBatchProcessingException to ensure failed messages return to your SQS queue The only difference is that SqsUtils Utility API will give you access to return from the processed messages if you need. Exception SQSBatchProcessingException thrown from the utility will have access to both successful and failed messaged along with failure exceptions.","title":"Processing messages from SQS"},{"location":"utilities/batch/#functional-interface-sqsmessagehandler","text":"Both annotation and SqsUtils Utility API requires an implementation of functional interface SqsMessageHandler . This implementation is responsible for processing each individual message from the batch, and to raise an exception if unable to process any of the messages sent. Any non-exception/successful return from your record handler function will instruct utility to queue up each individual message for deletion.","title":"Functional Interface SqsMessageHandler"},{"location":"utilities/batch/#sqsbatch-annotation","text":"When using this annotation, you need provide a class implementation of SqsMessageHandler that will process individual messages from the batch - It should raise an exception if it is unable to process the record. All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch: Any successfully processed messages , we will delete them from the queue via sqs:DeleteMessageBatch Any unprocessed messages detected , we will raise SQSBatchProcessingException to ensure failed messages return to your SQS queue Warning You will not have access to the processed messages within the Lambda Handler - all processing logic will and should be performed by the implemented SqsMessageHandler # process () function. AppSqsEvent.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class AppSqsEvent implements RequestHandler < SQSEvent , String > { @Override @SqsBatch ( SampleMessageHandler . class ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } public class SampleMessageHandler implements SqsMessageHandler < Object > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } }","title":"SqsBatch annotation"},{"location":"utilities/batch/#sqsutils-utility-api","text":"If you require access to the result of processed messages, you can use this utility. The result from calling SqsUtils # batchProcessor () on the context manager will be a list of all the return values from your SqsMessageHandler # process () function. You can also use the utility in functional way by providing inline implementation of functional interface SqsMessageHandler # process () Utility API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } } Function implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , ( message ) -> { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; }); return returnValues ; } }","title":"SqsUtils Utility API"},{"location":"utilities/batch/#passing-custom-sqsclient","text":"If you need to pass custom SqsClient such as region to the SDK, you can pass your own SqsClient to be used by utility either for SqsBatch annotation , or SqsUtils Utility API . App.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class AppSqsEvent implements RequestHandler < SQSEvent , List < String >> { static { SqsUtils . overrideSqsClient ( SqsClient . builder () . build ()); } @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , SampleMessageHandler . class ); return returnValues ; } public class SampleMessageHandler implements SqsMessageHandler < String > { @Override public String process ( SQSMessage message ) { // This will be called for each individual message from a batch // It should raise an exception if the message was not processed successfully String returnVal = doSomething ( message . getBody ()); return returnVal ; } } }","title":"Passing custom SqsClient"},{"location":"utilities/batch/#suppressing-exceptions","text":"If you want to disable the default behavior where SQSBatchProcessingException is raised if there are any exception, you can pass the suppressException boolean argument. Within SqsBatch annotation 1 2 3 4 5 @Override @SqsBatch ( value = SampleMessageHandler . class , suppressException = true ) public String handleRequest ( SQSEvent input , Context context ) { return \"{\\\"statusCode\\\": 200}\" ; } Within SqsUtils Utility API 1 2 3 4 5 6 @Override public List < String > handleRequest ( SQSEvent input , Context context ) { List < String > returnValues = SqsUtils . batchProcessor ( input , true , SampleMessageHandler . class ); return returnValues ; }","title":"Suppressing exceptions"},{"location":"utilities/parameters/","text":"The parameters utility provides a way to retrieve parameter values from AWS Systems Manager Parameter Store or AWS Secrets Manager . It also provides a base class to create your parameter provider implementation. Key features Retrieve one or multiple parameters from the underlying provider Cache parameter values for a given amount of time (defaults to 5 seconds) Transform parameter values from JSON or base 64 encoded strings Install \u00b6 To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> <version> 1.2.0 </version> </dependency> Gradle 1 2 3 4 5 dependencies { ... implementation 'software.amazon.lambda:powertools-parameters:1.2.0' aspectpath 'software.amazon.lambda:powertools-parameters:1.2.0' } IAM Permissions This utility requires additional permissions to work as expected. See the table below: Provider Function/Method IAM Permission SSM Parameter Store SSMProvider.get(String) SSMProvider.get(String, Class) ssm:GetParameter SSM Parameter Store SSMProvider.getMultiple(String) ssm:GetParametersByPath Secrets Manager SecretsProvider.get(String) SecretsProvider.get(String, Class) secretsmanager:GetSecretValue SSM Parameter Store \u00b6 You can retrieve a single parameter using SSMProvider.get() and pass the key of the parameter. For multiple parameters, you can use SSMProvider.getMultiple() and pass the path to retrieve them all. Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SSMProvider 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); } SSMProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SsmClient client = SsmClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider ( client ); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); } Additional arguments \u00b6 The AWS Systems Manager Parameter Store provider supports two additional arguments for the get() and getMultiple() methods: Option Default Description withDecryption() False Will automatically decrypt the parameter. recursive() False For getMultiple() only, will fetch all parameter values recursively based on a path prefix. Example: AppWithSSM.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter and decrypt it String value = ssmProvider . withDecryption (). get ( \"/my/parameter\" ); // Retrieve multiple parameters recursively from a path prefix Map < String , String > values = ssmProvider . recursive (). getMultiple ( \"/my/path/prefix\" ); } Secrets Manager \u00b6 For secrets stored in Secrets Manager, use getSecretsProvider . Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SecretsProvider 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider (); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); } SecretsProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); } Advanced configuration \u00b6 Caching \u00b6 By default, all parameters and their corresponding values are cached for 5 seconds. You can customize this default value using defaultMaxAge . You can also customize this value for each parameter using withMaxAge . Provider with default Max age 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider () . defaultMaxAge ( 10 , ChronoUnit . SECONDS ); String value = secretsProvider . get ( \"/my/secret\" ); } Provider with age for each param 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); String value = secretsProvider . withMaxAge ( 10 , ChronoUnit . SECONDS ). get ( \"/my/secret\" ); } Transform values \u00b6 Parameter values can be transformed using withTransformation(transformerClass) . Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize- SSMProvider.getMultiple() does not support transformation and will return simple Strings. Base64 Transformation 1 2 3 String value = provider . withTransformation ( Transformer . base64 ) . get ( \"/my/parameter/b64\" ); Complex Transformation 1 2 3 MyObj object = provider . withTransformation ( Transformer . json ) . get ( \"/my/parameter/json\" , MyObj . class ); Write your own Transformer \u00b6 You can write your own transformer, by implementing the Transformer interface and the applyTransformation() method. For example, if you wish to deserialize XML into an object. XmlTransformer.java 1 2 3 4 5 6 7 8 9 10 11 12 13 public class XmlTransformer < T > implements Transformer < T > { private final XmlMapper mapper = new XmlMapper (); @Override public T applyTransformation ( String value , Class < T > targetClass ) throws TransformationException { try { return mapper . readValue ( value , targetClass ); } catch ( IOException e ) { throw new TransformationException ( e ); } } } Using XmlTransformer 1 2 3 MyObj object = provider . withTransformation ( XmlTransformer . class ) . get ( \"/my/parameter/xml\" , MyObj . class ); Fluent API \u00b6 To simplify the use of the library, you can chain all method calls before a get. Fluent API call 1 2 3 4 5 6 ssmProvider . defaultMaxAge ( 10 , SECONDS ) // will set 10 seconds as the default cache TTL . withMaxAge ( 1 , MINUTES ) // will set the cache TTL for this value at 1 minute . withTransformation ( json ) // json is a static import from Transformer.json . withDecryption () // enable decryption of the parameter value . get ( \"/my/param\" , MyObj . class ); // finally get the value Create your own provider \u00b6 You can create your own custom parameter store provider by inheriting the BaseProvider class and implementing the String getValue(String key) method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class. Example implementation using S3 as a custom parameter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class S3Provider extends BaseProvider { private final S3Client client ; private String bucket ; S3Provider ( CacheManager cacheManager ) { this ( cacheManager , S3Client . create ()); } S3Provider ( CacheManager cacheManager , S3Client client ) { super ( cacheManager ); this . client = client ; } public S3Provider withBucket ( String bucket ) { this . bucket = bucket ; return this ; } @Override protected String getValue ( String key ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } GetObjectRequest request = GetObjectRequest . builder (). bucket ( bucket ). key ( key ). build (); ResponseBytes < GetObjectResponse > response = client . getObject ( request , ResponseTransformer . toBytes ()); return response . asUtf8String (); } @Override protected Map < String , String > getMultipleValues ( String path ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } ListObjectsV2Request listRequest = ListObjectsV2Request . builder (). bucket ( bucket ). prefix ( path ). build (); List < S3Object > s3Objects = client . listObjectsV2 ( listRequest ). contents (); Map < String , String > result = new HashMap <> (); s3Objects . forEach ( s3Object -> { result . put ( s3Object . key (), getValue ( s3Object . key ())); }); return result ; } @Override protected void resetToDefaults () { super . resetToDefaults (); bucket = null ; } } Using custom parameter store 1 2 3 4 5 S3Provider provider = new S3Provider ( ParamManager . getCacheManager ()); provider . setTransformationManager ( ParamManager . getTransformationManager ()); String value = provider . withBucket ( \"myBucket\" ). get ( \"myKey\" ); Annotation \u00b6 You can make use of the annotation @Param to inject a parameter value in a variable. By default, it will use SSMProvider to retrieve the value from AWS System Manager Parameter Store. You could specify a different provider as long as it extends BaseProvider and/or a Transformer . Param Annotation 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" ) ObjectToDeserialize value ; } Custom Provider Usage 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" provider = SecretsProvider . class , transformer = JsonTransformer . class ) ObjectToDeserialize value ; } In this case SecretsProvider will be used to retrieve a raw value that is then trasformed into the target Object by using JsonTransformer . To show the convenience of the annotation compare the following two code snippets. Install \u00b6 If you want to use the @Param annotation in your project add configuration to compile-time weave (CTW) the powertools-parameters aspects into your project. Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> ... <aspectLibraries> ... <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Note: If you are working with lambda function on runtime post java8, please refer issue for workaround Gradle 1 2 3 4 5 6 7 8 9 10 11 12 plugins { id 'java' id 'aspectj.AspectjGradlePlugin' version '0.0.6' } repositories { jcenter () } dependencies { ... implementation 'software.amazon.lambda:powertools-parameters:1.2.0' aspectpath 'software.amazon.lambda:powertools-parameters:1.2.0' } Note: Please add aspectjVersion = '1.9.6' to the gradle.properties file. The aspectj plugin works at the moment with gradle 5.x only if you are using java 8 as runtime. Please refer to open issue for more details.","title":"Parameters"},{"location":"utilities/parameters/#install","text":"To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> <version> 1.2.0 </version> </dependency> Gradle 1 2 3 4 5 dependencies { ... implementation 'software.amazon.lambda:powertools-parameters:1.2.0' aspectpath 'software.amazon.lambda:powertools-parameters:1.2.0' } IAM Permissions This utility requires additional permissions to work as expected. See the table below: Provider Function/Method IAM Permission SSM Parameter Store SSMProvider.get(String) SSMProvider.get(String, Class) ssm:GetParameter SSM Parameter Store SSMProvider.getMultiple(String) ssm:GetParametersByPath Secrets Manager SecretsProvider.get(String) SecretsProvider.get(String, Class) secretsmanager:GetSecretValue","title":"Install"},{"location":"utilities/parameters/#ssm-parameter-store","text":"You can retrieve a single parameter using SSMProvider.get() and pass the key of the parameter. For multiple parameters, you can use SSMProvider.getMultiple() and pass the path to retrieve them all. Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SSMProvider 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); } SSMProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SsmClient client = SsmClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider ( client ); // Retrieve a single parameter String value = ssmProvider . get ( \"/my/parameter\" ); // Retrieve multiple parameters from a path prefix // This returns a Map with the parameter name as key Map < String , String > values = ssmProvider . getMultiple ( \"/my/path/prefix\" ); }","title":"SSM Parameter Store"},{"location":"utilities/parameters/#additional-arguments","text":"The AWS Systems Manager Parameter Store provider supports two additional arguments for the get() and getMultiple() methods: Option Default Description withDecryption() False Will automatically decrypt the parameter. recursive() False For getMultiple() only, will fetch all parameter values recursively based on a path prefix. Example: AppWithSSM.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import software.amazon.lambda.powertools.parameters.SSMProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSSM implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the SSM Provider SSMProvider ssmProvider = ParamManager . getSsmProvider (); // Retrieve a single parameter and decrypt it String value = ssmProvider . withDecryption (). get ( \"/my/parameter\" ); // Retrieve multiple parameters recursively from a path prefix Map < String , String > values = ssmProvider . recursive (). getMultiple ( \"/my/path/prefix\" ); }","title":"Additional arguments"},{"location":"utilities/parameters/#secrets-manager","text":"For secrets stored in Secrets Manager, use getSecretsProvider . Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials. SecretsProvider 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider (); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); } SecretsProvider with an explicit region 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); // Retrieve a single secret String value = secretsProvider . get ( \"/my/secret\" ); }","title":"Secrets Manager"},{"location":"utilities/parameters/#advanced-configuration","text":"","title":"Advanced configuration"},{"location":"utilities/parameters/#caching","text":"By default, all parameters and their corresponding values are cached for 5 seconds. You can customize this default value using defaultMaxAge . You can also customize this value for each parameter using withMaxAge . Provider with default Max age 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { // Get an instance of the Secrets Provider SecretsProvider secretsProvider = ParamManager . getSecretsProvider () . defaultMaxAge ( 10 , ChronoUnit . SECONDS ); String value = secretsProvider . get ( \"/my/secret\" ); } Provider with age for each param 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.parameters.SecretsProvider ; import software.amazon.lambda.powertools.parameters.ParamManager ; public class AppWithSecrets implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { SecretsManagerClient client = SecretsManagerClient . builder (). region ( Region . EU_CENTRAL_1 ). build (); SecretsProvider secretsProvider = ParamManager . getSecretsProvider ( client ); String value = secretsProvider . withMaxAge ( 10 , ChronoUnit . SECONDS ). get ( \"/my/secret\" ); }","title":"Caching"},{"location":"utilities/parameters/#transform-values","text":"Parameter values can be transformed using withTransformation(transformerClass) . Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize- SSMProvider.getMultiple() does not support transformation and will return simple Strings. Base64 Transformation 1 2 3 String value = provider . withTransformation ( Transformer . base64 ) . get ( \"/my/parameter/b64\" ); Complex Transformation 1 2 3 MyObj object = provider . withTransformation ( Transformer . json ) . get ( \"/my/parameter/json\" , MyObj . class );","title":"Transform values"},{"location":"utilities/parameters/#write-your-own-transformer","text":"You can write your own transformer, by implementing the Transformer interface and the applyTransformation() method. For example, if you wish to deserialize XML into an object. XmlTransformer.java 1 2 3 4 5 6 7 8 9 10 11 12 13 public class XmlTransformer < T > implements Transformer < T > { private final XmlMapper mapper = new XmlMapper (); @Override public T applyTransformation ( String value , Class < T > targetClass ) throws TransformationException { try { return mapper . readValue ( value , targetClass ); } catch ( IOException e ) { throw new TransformationException ( e ); } } } Using XmlTransformer 1 2 3 MyObj object = provider . withTransformation ( XmlTransformer . class ) . get ( \"/my/parameter/xml\" , MyObj . class );","title":"Write your own Transformer"},{"location":"utilities/parameters/#fluent-api","text":"To simplify the use of the library, you can chain all method calls before a get. Fluent API call 1 2 3 4 5 6 ssmProvider . defaultMaxAge ( 10 , SECONDS ) // will set 10 seconds as the default cache TTL . withMaxAge ( 1 , MINUTES ) // will set the cache TTL for this value at 1 minute . withTransformation ( json ) // json is a static import from Transformer.json . withDecryption () // enable decryption of the parameter value . get ( \"/my/param\" , MyObj . class ); // finally get the value","title":"Fluent API"},{"location":"utilities/parameters/#create-your-own-provider","text":"You can create your own custom parameter store provider by inheriting the BaseProvider class and implementing the String getValue(String key) method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class. Example implementation using S3 as a custom parameter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class S3Provider extends BaseProvider { private final S3Client client ; private String bucket ; S3Provider ( CacheManager cacheManager ) { this ( cacheManager , S3Client . create ()); } S3Provider ( CacheManager cacheManager , S3Client client ) { super ( cacheManager ); this . client = client ; } public S3Provider withBucket ( String bucket ) { this . bucket = bucket ; return this ; } @Override protected String getValue ( String key ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } GetObjectRequest request = GetObjectRequest . builder (). bucket ( bucket ). key ( key ). build (); ResponseBytes < GetObjectResponse > response = client . getObject ( request , ResponseTransformer . toBytes ()); return response . asUtf8String (); } @Override protected Map < String , String > getMultipleValues ( String path ) { if ( bucket == null ) { throw new IllegalStateException ( \"A bucket must be specified, using withBucket() method\" ); } ListObjectsV2Request listRequest = ListObjectsV2Request . builder (). bucket ( bucket ). prefix ( path ). build (); List < S3Object > s3Objects = client . listObjectsV2 ( listRequest ). contents (); Map < String , String > result = new HashMap <> (); s3Objects . forEach ( s3Object -> { result . put ( s3Object . key (), getValue ( s3Object . key ())); }); return result ; } @Override protected void resetToDefaults () { super . resetToDefaults (); bucket = null ; } } Using custom parameter store 1 2 3 4 5 S3Provider provider = new S3Provider ( ParamManager . getCacheManager ()); provider . setTransformationManager ( ParamManager . getTransformationManager ()); String value = provider . withBucket ( \"myBucket\" ). get ( \"myKey\" );","title":"Create your own provider"},{"location":"utilities/parameters/#annotation","text":"You can make use of the annotation @Param to inject a parameter value in a variable. By default, it will use SSMProvider to retrieve the value from AWS System Manager Parameter Store. You could specify a different provider as long as it extends BaseProvider and/or a Transformer . Param Annotation 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" ) ObjectToDeserialize value ; } Custom Provider Usage 1 2 3 4 5 6 public class AppWithAnnotation implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Param ( key = \"/my/parameter/json\" provider = SecretsProvider . class , transformer = JsonTransformer . class ) ObjectToDeserialize value ; } In this case SecretsProvider will be used to retrieve a raw value that is then trasformed into the target Object by using JsonTransformer . To show the convenience of the annotation compare the following two code snippets.","title":"Annotation"},{"location":"utilities/parameters/#install_1","text":"If you want to use the @Param annotation in your project add configuration to compile-time weave (CTW) the powertools-parameters aspects into your project. Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> ... <aspectLibraries> ... <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-parameters </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Note: If you are working with lambda function on runtime post java8, please refer issue for workaround Gradle 1 2 3 4 5 6 7 8 9 10 11 12 plugins { id 'java' id 'aspectj.AspectjGradlePlugin' version '0.0.6' } repositories { jcenter () } dependencies { ... implementation 'software.amazon.lambda:powertools-parameters:1.2.0' aspectpath 'software.amazon.lambda:powertools-parameters:1.2.0' } Note: Please add aspectjVersion = '1.9.6' to the gradle.properties file. The aspectj plugin works at the moment with gradle 5.x only if you are using java 8 as runtime. Please refer to open issue for more details.","title":"Install"},{"location":"utilities/sqs_large_message_handling/","text":"The large message handling utility handles SQS messages which have had their payloads offloaded to S3 due to them being larger than the SQS maximum. The utility automatically retrieves messages which have been offloaded to S3 using the amazon-sqs-java-extended-client-lib client library. Once the message payloads have been processed successful the utility can delete the message payloads from S3. This utility is compatible with versions 1.1.0+ of amazon-sqs-java-extended-client-lib. Maven 1 2 3 4 5 <dependency> <groupId> com.amazonaws </groupId> <artifactId> amazon-sqs-java-extended-client-lib </artifactId> <version> 1.1.0 </version> </dependency> Gradle 1 2 3 dependencies { implementation 'com.amazonaws:amazon-sqs-java-extended-client-lib:1.1.0' } Install \u00b6 To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.2.0 </version> </dependency> Maven Configuration Configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project. You may already have this plugin in your pom. In that case add the dependency to the aspectLibraries section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Gradle 1 2 3 4 5 dependencies { ... implementation 'software.amazon.lambda:powertools-sqs:1.2.0' aspectpath 'software.amazon.lambda:powertools-sqs:1.2.0' } Lambda handler \u00b6 The annotation @SqsLargeMessage should be used with the handleRequest method of a class which implements com.amazonaws.services.lambda.runtime.RequestHandler with com.amazonaws.services.lambda.runtime.events.SQSEvent as the first parameter. SqsMessageHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override @SqsLargeMessage public String handleRequest ( SQSEvent sqsEvent , Context context ) { // process messages return \"ok\" ; } } @SqsLargeMessage creates a default S3 Client AmazonS3 amazonS3 = AmazonS3ClientBuilder.defaultClient() . Tip When the Lambda function is invoked with an event from SQS, each received record in the SQSEvent is checked to see to validate if it is offloaded to S3. If it does then getObject(bucket, key) will be called, and the payload retrieved. If there is an error during this process then the function will fail with a FailedProcessingLargePayloadException exception. If the request handler method returns without error then each payload will be deleted from S3 using deleteObject(bucket, key) To disable deletion of payloads setting the following annotation parameter: Disable payload deletion 1 2 3 4 5 6 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; @SqsLargeMessage ( deletePayloads = false ) public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { } Utility \u00b6 If you want to avoid using annotation and have control over error that can happen during payload enrichment use SqsUtils.enrichedMessageFromS3() . It provides you access with list of SQSMessage object enriched from S3 payload. Original SQSEvent object is never mutated. You can also control if the S3 payload should be deleted after successful processing. Functional API without annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override public String handleRequest ( SQSEvent sqsEvent , Context context ) { Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Do not delete payload after processing. Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Better control over exception during enrichment try { // Do not delete payload after processing. SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic }); } catch ( FailedProcessingLargePayloadException e ) { // handle any exception. } return \"ok\" ; } }","title":"SQS Large Message Handling"},{"location":"utilities/sqs_large_message_handling/#install","text":"To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 <dependency> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> <version> 1.2.0 </version> </dependency> Maven Configuration Configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project. You may already have this plugin in your pom. In that case add the dependency to the aspectLibraries section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-sqs </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Gradle 1 2 3 4 5 dependencies { ... implementation 'software.amazon.lambda:powertools-sqs:1.2.0' aspectpath 'software.amazon.lambda:powertools-sqs:1.2.0' }","title":"Install"},{"location":"utilities/sqs_large_message_handling/#lambda-handler","text":"The annotation @SqsLargeMessage should be used with the handleRequest method of a class which implements com.amazonaws.services.lambda.runtime.RequestHandler with com.amazonaws.services.lambda.runtime.events.SQSEvent as the first parameter. SqsMessageHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override @SqsLargeMessage public String handleRequest ( SQSEvent sqsEvent , Context context ) { // process messages return \"ok\" ; } } @SqsLargeMessage creates a default S3 Client AmazonS3 amazonS3 = AmazonS3ClientBuilder.defaultClient() . Tip When the Lambda function is invoked with an event from SQS, each received record in the SQSEvent is checked to see to validate if it is offloaded to S3. If it does then getObject(bucket, key) will be called, and the payload retrieved. If there is an error during this process then the function will fail with a FailedProcessingLargePayloadException exception. If the request handler method returns without error then each payload will be deleted from S3 using deleteObject(bucket, key) To disable deletion of payloads setting the following annotation parameter: Disable payload deletion 1 2 3 4 5 6 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; @SqsLargeMessage ( deletePayloads = false ) public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { }","title":"Lambda handler"},{"location":"utilities/sqs_large_message_handling/#utility","text":"If you want to avoid using annotation and have control over error that can happen during payload enrichment use SqsUtils.enrichedMessageFromS3() . It provides you access with list of SQSMessage object enriched from S3 payload. Original SQSEvent object is never mutated. You can also control if the S3 payload should be deleted after successful processing. Functional API without annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import software.amazon.lambda.powertools.sqs.SqsLargeMessage ; import software.amazon.lambda.powertools.sqs.SqsUtils ; public class SqsMessageHandler implements RequestHandler < SQSEvent , String > { @Override public String handleRequest ( SQSEvent sqsEvent , Context context ) { Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Do not delete payload after processing. Map < String , String > sqsMessage = SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic Map < String , String > someBusinessLogic = new HashMap <> (); someBusinessLogic . put ( \"Message\" , sqsMessages . get ( 0 ). getBody ()); return someBusinessLogic ; }); // Better control over exception during enrichment try { // Do not delete payload after processing. SqsUtils . enrichedMessageFromS3 ( sqsEvent , false , sqsMessages -> { // Some business logic }); } catch ( FailedProcessingLargePayloadException e ) { // handle any exception. } return \"ok\" ; } }","title":"Utility"},{"location":"utilities/validation/","text":"This utility provides JSON Schema validation for payloads held within events and response used in AWS Lambda. Key features Validate incoming events and responses Built-in validation for most common events (API Gateway, SNS, SQS, ...) JMESPath support validate only a sub part of the event Install \u00b6 To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 <dependency> <groupId> com.amazonaws </groupId> <artifactId> powertools-validation </artifactId> <version> 1.2.0 </version> </dependency> Maven Configuration Configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project. You may already have this plugin in your pom. In that case add the dependency to the aspectLibraries section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-validation </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Gradle 1 2 3 4 dependencies { implementation 'software.amazon.lambda:powertools-validation:1.2.0' aspectpath 'software.amazon.lambda:powertools-validation:1.2.0' } Validating events \u00b6 You can validate inbound and outbound events using @Validation annotation. You can also use the Validator#validate() methods, if you want more control over the validation process such as handling a validation error. We support JSON schema version 4, 6, 7 and 201909 (from jmespath-jackson library ). Validation annotation \u00b6 @Validation annotation is used to validate either inbound events or functions' response. It will fail fast with ValidationException if an event or response doesn't conform with given JSON Schema. While it is easier to specify a json schema file in the classpath (using the notation \"classpath:/path/to/schema.json\" ), you can also provide a JSON String containing the schema. MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override @Validation ( inboundSchema = \"classpath:/schema_in.json\" , outboundSchema = \"classpath:/schema_out.json\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // ... return something ; } } NOTE : It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both. Validate function \u00b6 Validate standalone function is used within the Lambda handler, or any other methods that perform data validation. You can also gracefully handle schema validation errors by catching ValidationException . MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import static software.amazon.lambda.powertools.validation.ValidationUtils.* ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { try { validate ( input , \"classpath:/schema.json\" ); } catch ( ValidationException ex ) { // do something before throwing it throw ex ; } // ... return something ; } } NOTE : Schemas are stored in memory for reuse, to avoid loading them from file each time. Built-in events and responses \u00b6 For the following events and responses, the Validator will automatically perform validation on the content. Events Type of event Class Path to content API Gateway REST APIGatewayProxyRequestEvent body API Gateway HTTP APIGatewayV2HTTPEvent body Application Load Balancer ApplicationLoadBalancerRequestEvent body Cloudformation Custom Resource CloudFormationCustomResourceEvent resourceProperties CloudWatch Logs CloudWatchLogsEvent awslogs.powertools_base64_gzip(data) EventBridge / Cloudwatch ScheduledEvent detail Kafka KafkaEvent records[*][*].value Kinesis KinesisEvent Records[*].kinesis.powertools_base64(data) Kinesis Firehose KinesisFirehoseEvent Records[*].powertools_base64(data) Kinesis Analytics from Firehose KinesisAnalyticsFirehoseInputPreprocessingEvent Records[*].powertools_base64(data) Kinesis Analytics from Streams KinesisAnalyticsStreamsInputPreprocessingEvent Records[*].powertools_base64(data) SNS SNSEvent Records[*].Sns.Message SQS SQSEvent Records[*].body Responses Type of response Class Path to content (envelope) API Gateway REST APIGatewayProxyResponseEvent} body API Gateway HTTP APIGatewayV2HTTPResponse} body API Gateway WebSocket APIGatewayV2WebSocketResponse} body Load Balancer ApplicationLoadBalancerResponseEvent} body Kinesis Analytics KinesisAnalyticsInputPreprocessingResponse} `Records[*].powertools_base64(data)`` Custom events and responses \u00b6 You can also validate any Event or Response type, once you have the appropriate schema. Sometimes, you might want to validate only a portion of it - This is where the envelope parameter is for. Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation. MyCustomEventHandler.java 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyCustomEventHandler implements RequestHandler < MyCustomEvent , String > { @Override @Validation ( inboundSchema = \"classpath:/my_custom_event_schema.json\" , envelope = \"basket.products[*]\" ) public String handleRequest ( MyCustomEvent input , Context context ) { return \"OK\" ; } } my_custom_event_schema.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"basket\" : { \"products\" : [ { \"id\" : 43242 , \"name\" : \"FooBar XY\" , \"price\" : 258 }, { \"id\" : 765 , \"name\" : \"BarBaz AB\" , \"price\" : 43.99 } ] } } This is quite powerful because you can use JMESPath Query language to extract records from arrays, slice and dice , to pipe expressions and function expressions, where you'd extract what you need before validating the actual payload. JMESPath functions \u00b6 JMESPath functions ensure to make an operation on a specific part of the json.validate Powertools provides two built-in functions: powertools_base64 function \u00b6 Use powertools_base64 function to decode any base64 data. Below sample will decode the base64 value within the data key, and decode the JSON string into a valid JSON before we can validate it. MyEventHandler.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64(data)\" ); return \"OK\" ; } } schema.json 1 2 3 { \"data\" : \"ewogICJpZCI6IDQzMjQyLAogICJuYW1lIjogIkZvb0JhciBYWSIsCiAgInByaWNlIjogMjU4Cn0=\" } powertools_base64_gzip function \u00b6 Use powertools_base64_gzip function to decompress and decode base64 data. Below sample will decompress and decode base64 data. MyEventHandler.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64_gzip(data)\" ); return \"OK\" ; } } schema.json 1 2 3 { \"data\" : \"H4sIAAAAAAAA/6vmUlBQykxRslIwMTYyMdIBcfMSc1OBAkpu+flOiUUKEZFKYOGCosxkkLiRqQVXLQDnWo6bOAAAAA==\" } Note You don't need any function to transform a JSON String into a JSON object, powertools-validation will do it for you. In the 2 previous example, data contains JSON. Just provide the function to transform the base64 / gzipped / ... string into a clear JSON string. Bring your own JMESPath function \u00b6 Warning This should only be used for advanced use cases where you have special formats not covered by the built-in functions. New functions will be added to the 2 built-in ones. Your function must extend io.burt.jmespath.function.BaseFunction , take a String as parameter and return a String. You can read the doc for more information. Below is an example that takes some xml and transform it into json. Once your function is created, you need to add it to powertools.You can then use it to do your validation or using annotation. XMLFunction.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class XMLFunction extends BaseFunction { public Base64Function () { super ( \"powertools_xml\" , ArgumentConstraints . typeOf ( JmesPathType . STRING )); } @Override protected < T > T callFunction ( Adapter < T > runtime , List < FunctionArgument < T >> arguments ) { T value = arguments . get ( 0 ). value (); String xmlString = runtime . toString ( value ); String jsonString = // ... transform xmlString to json return runtime . createString ( jsonString ); } } Handler with validation API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.ValidationUtils.validate ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override public String handleRequest ( MyEventWithXML myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_xml(path.to.xml_data)\" ); return \"OK\" ; } } Handler with validation annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } } Change the schema version \u00b6 By default, powertools-validation is configured with V7 . You can use the ValidationConfig to change that behaviour. Handler with custom schema version 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). setSchemaVersion ( SpecVersion . VersionFlag . V4 ); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } } Advanced ObjectMapper settings \u00b6 If you need to configure the Jackson ObjectMapper, you can use the ValidationConfig : Handler with custom ObjectMapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ObjectMapper objectMapper = ValidationConfig . get (). getObjectMapper (); // update (de)serializationConfig or other properties } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Validation"},{"location":"utilities/validation/#install","text":"To install this utility, add the following dependency to your project. Maven 1 2 3 4 5 <dependency> <groupId> com.amazonaws </groupId> <artifactId> powertools-validation </artifactId> <version> 1.2.0 </version> </dependency> Maven Configuration Configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project. You may already have this plugin in your pom. In that case add the dependency to the aspectLibraries section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 <build> <plugins> ... <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> aspectj-maven-plugin </artifactId> <version> 1.11 </version> <configuration> <source> 1.8 </source> <target> 1.8 </target> <complianceLevel> 1.8 </complianceLevel> <aspectLibraries> <aspectLibrary> <groupId> software.amazon.lambda </groupId> <artifactId> powertools-validation </artifactId> </aspectLibrary> </aspectLibraries> </configuration> <executions> <execution> <goals> <goal> compile </goal> </goals> </execution> </executions> </plugin> ... </plugins> </build> Gradle 1 2 3 4 dependencies { implementation 'software.amazon.lambda:powertools-validation:1.2.0' aspectpath 'software.amazon.lambda:powertools-validation:1.2.0' }","title":"Install"},{"location":"utilities/validation/#validating-events","text":"You can validate inbound and outbound events using @Validation annotation. You can also use the Validator#validate() methods, if you want more control over the validation process such as handling a validation error. We support JSON schema version 4, 6, 7 and 201909 (from jmespath-jackson library ).","title":"Validating events"},{"location":"utilities/validation/#validation-annotation","text":"@Validation annotation is used to validate either inbound events or functions' response. It will fail fast with ValidationException if an event or response doesn't conform with given JSON Schema. While it is easier to specify a json schema file in the classpath (using the notation \"classpath:/path/to/schema.json\" ), you can also provide a JSON String containing the schema. MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override @Validation ( inboundSchema = \"classpath:/schema_in.json\" , outboundSchema = \"classpath:/schema_out.json\" ) public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { // ... return something ; } } NOTE : It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both.","title":"Validation annotation"},{"location":"utilities/validation/#validate-function","text":"Validate standalone function is used within the Lambda handler, or any other methods that perform data validation. You can also gracefully handle schema validation errors by catching ValidationException . MyFunctionHandler.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import static software.amazon.lambda.powertools.validation.ValidationUtils.* ; public class MyFunctionHandler implements RequestHandler < APIGatewayProxyRequestEvent , APIGatewayProxyResponseEvent > { @Override public APIGatewayProxyResponseEvent handleRequest ( APIGatewayProxyRequestEvent input , Context context ) { try { validate ( input , \"classpath:/schema.json\" ); } catch ( ValidationException ex ) { // do something before throwing it throw ex ; } // ... return something ; } } NOTE : Schemas are stored in memory for reuse, to avoid loading them from file each time.","title":"Validate function"},{"location":"utilities/validation/#built-in-events-and-responses","text":"For the following events and responses, the Validator will automatically perform validation on the content. Events Type of event Class Path to content API Gateway REST APIGatewayProxyRequestEvent body API Gateway HTTP APIGatewayV2HTTPEvent body Application Load Balancer ApplicationLoadBalancerRequestEvent body Cloudformation Custom Resource CloudFormationCustomResourceEvent resourceProperties CloudWatch Logs CloudWatchLogsEvent awslogs.powertools_base64_gzip(data) EventBridge / Cloudwatch ScheduledEvent detail Kafka KafkaEvent records[*][*].value Kinesis KinesisEvent Records[*].kinesis.powertools_base64(data) Kinesis Firehose KinesisFirehoseEvent Records[*].powertools_base64(data) Kinesis Analytics from Firehose KinesisAnalyticsFirehoseInputPreprocessingEvent Records[*].powertools_base64(data) Kinesis Analytics from Streams KinesisAnalyticsStreamsInputPreprocessingEvent Records[*].powertools_base64(data) SNS SNSEvent Records[*].Sns.Message SQS SQSEvent Records[*].body Responses Type of response Class Path to content (envelope) API Gateway REST APIGatewayProxyResponseEvent} body API Gateway HTTP APIGatewayV2HTTPResponse} body API Gateway WebSocket APIGatewayV2WebSocketResponse} body Load Balancer ApplicationLoadBalancerResponseEvent} body Kinesis Analytics KinesisAnalyticsInputPreprocessingResponse} `Records[*].powertools_base64(data)``","title":"Built-in events and responses"},{"location":"utilities/validation/#custom-events-and-responses","text":"You can also validate any Event or Response type, once you have the appropriate schema. Sometimes, you might want to validate only a portion of it - This is where the envelope parameter is for. Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation. MyCustomEventHandler.java 1 2 3 4 5 6 7 8 9 10 11 import software.amazon.lambda.powertools.validation.Validation ; public class MyCustomEventHandler implements RequestHandler < MyCustomEvent , String > { @Override @Validation ( inboundSchema = \"classpath:/my_custom_event_schema.json\" , envelope = \"basket.products[*]\" ) public String handleRequest ( MyCustomEvent input , Context context ) { return \"OK\" ; } } my_custom_event_schema.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"basket\" : { \"products\" : [ { \"id\" : 43242 , \"name\" : \"FooBar XY\" , \"price\" : 258 }, { \"id\" : 765 , \"name\" : \"BarBaz AB\" , \"price\" : 43.99 } ] } } This is quite powerful because you can use JMESPath Query language to extract records from arrays, slice and dice , to pipe expressions and function expressions, where you'd extract what you need before validating the actual payload.","title":"Custom events and responses"},{"location":"utilities/validation/#jmespath-functions","text":"JMESPath functions ensure to make an operation on a specific part of the json.validate Powertools provides two built-in functions:","title":"JMESPath functions"},{"location":"utilities/validation/#powertools_base64-function","text":"Use powertools_base64 function to decode any base64 data. Below sample will decode the base64 value within the data key, and decode the JSON string into a valid JSON before we can validate it. MyEventHandler.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64(data)\" ); return \"OK\" ; } } schema.json 1 2 3 { \"data\" : \"ewogICJpZCI6IDQzMjQyLAogICJuYW1lIjogIkZvb0JhciBYWSIsCiAgInByaWNlIjogMjU4Cn0=\" }","title":"powertools_base64 function"},{"location":"utilities/validation/#powertools_base64_gzip-function","text":"Use powertools_base64_gzip function to decompress and decode base64 data. Below sample will decompress and decode base64 data. MyEventHandler.java 1 2 3 4 5 6 7 8 9 10 import software.amazon.lambda.powertools.validation.ValidationUtils ; public class MyEventHandler implements RequestHandler < MyEvent , String > { @Override public String handleRequest ( MyEvent myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_base64_gzip(data)\" ); return \"OK\" ; } } schema.json 1 2 3 { \"data\" : \"H4sIAAAAAAAA/6vmUlBQykxRslIwMTYyMdIBcfMSc1OBAkpu+flOiUUKEZFKYOGCosxkkLiRqQVXLQDnWo6bOAAAAA==\" } Note You don't need any function to transform a JSON String into a JSON object, powertools-validation will do it for you. In the 2 previous example, data contains JSON. Just provide the function to transform the base64 / gzipped / ... string into a clear JSON string.","title":"powertools_base64_gzip function"},{"location":"utilities/validation/#bring-your-own-jmespath-function","text":"Warning This should only be used for advanced use cases where you have special formats not covered by the built-in functions. New functions will be added to the 2 built-in ones. Your function must extend io.burt.jmespath.function.BaseFunction , take a String as parameter and return a String. You can read the doc for more information. Below is an example that takes some xml and transform it into json. Once your function is created, you need to add it to powertools.You can then use it to do your validation or using annotation. XMLFunction.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class XMLFunction extends BaseFunction { public Base64Function () { super ( \"powertools_xml\" , ArgumentConstraints . typeOf ( JmesPathType . STRING )); } @Override protected < T > T callFunction ( Adapter < T > runtime , List < FunctionArgument < T >> arguments ) { T value = arguments . get ( 0 ). value (); String xmlString = runtime . toString ( value ); String jsonString = // ... transform xmlString to json return runtime . createString ( jsonString ); } } Handler with validation API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.ValidationUtils.validate ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override public String handleRequest ( MyEventWithXML myEvent , Context context ) { validate ( myEvent , \"classpath:/schema.json\" , \"powertools_xml(path.to.xml_data)\" ); return \"OK\" ; } } Handler with validation annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). addFunction ( new XMLFunction ()); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Bring your own JMESPath function"},{"location":"utilities/validation/#change-the-schema-version","text":"By default, powertools-validation is configured with V7 . You can use the ValidationConfig to change that behaviour. Handler with custom schema version 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ValidationConfig . get (). setSchemaVersion ( SpecVersion . VersionFlag . V4 ); } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Change the schema version"},{"location":"utilities/validation/#advanced-objectmapper-settings","text":"If you need to configure the Jackson ObjectMapper, you can use the ValidationConfig : Handler with custom ObjectMapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... import software.amazon.lambda.powertools.validation.ValidationConfig ; import software.amazon.lambda.powertools.validation.Validation ; static { ObjectMapper objectMapper = ValidationConfig . get (). getObjectMapper (); // update (de)serializationConfig or other properties } public class MyXMLEventHandler implements RequestHandler < MyEventWithXML , String > { @Override @Validation ( inboundSchema = \"classpath:/schema.json\" , envelope = \"powertools_xml(path.to.xml_data)\" ) public String handleRequest ( MyEventWithXML myEvent , Context context ) { return \"OK\" ; } }","title":"Advanced ObjectMapper settings"}]}